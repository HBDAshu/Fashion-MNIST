{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshanand2327/Fashion-MNIST/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1dpHI30R_k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnN_7mZeS4iv",
        "colab_type": "code",
        "outputId": "00771028-eae3-4591-f7f0-c57195bedef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = datasets.FashionMNIST(\"fashion_MNIST\", train = True, transform=transform, download = True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 64, shuffle=True)\n",
        "\n",
        "testset = datasets.FashionMNIST(\"fashion_MNIST\", train=False, transform=transform, download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle = True)\n",
        "\n",
        "dataIter = iter(trainloader)\n",
        "images, labels = dataIter.next()\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap = 'Greys_r')\n",
        "print(labels[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to fashion_MNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 10984337.05it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting fashion_MNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to fashion_MNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 71166.10it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting fashion_MNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to fashion_MNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 2954772.22it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting fashion_MNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to fashion_MNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 27153.05it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting fashion_MNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCx+oqBY/ERBsfiJgmLxEwXF4icK6v8BcgevVcJiM4UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYNBtF8PhTPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "class classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.hidden3 = nn.Linear(128, 64)\n",
        "    self.output = nn.Linear(64, 10)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "  def forward(self, x):\n",
        "   \n",
        "    x = self.dropout(F.relu(self.hidden1(x)))\n",
        "    x = self.dropout(F.relu(self.hidden2(x)))\n",
        "    x = self.dropout(F.relu(self.hidden3(x)))\n",
        "    x = F.log_softmax(self.output(x), dim=1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLIp4kIl0Hod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = classifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80fTOAqkhzFu",
        "colab_type": "code",
        "outputId": "9c224c82-99ba-4e3f-c68b-486f7fbece19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (hidden2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (hidden3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEGgCHGpkpfY",
        "colab_type": "code",
        "outputId": "86a98786-7995-48fe-baba-5de18a941fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    prediction = model(images)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(prediction, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Training loss:  {running_loss/len(trainloader)}\")\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "      images = images.view(images.shape[0], -1)\n",
        "      outputs = model(images)\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (pred == labels).sum().item()\n",
        "    print('Accuracy:', correct/total)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss:  0.3823780888624029\n",
            "Accuracy: 0.8462\n",
            "Training loss:  0.3714196678481376\n",
            "Accuracy: 0.853\n",
            "Training loss:  0.3759099246660021\n",
            "Accuracy: 0.8449\n",
            "Training loss:  0.3717298862029876\n",
            "Accuracy: 0.8531\n",
            "Training loss:  0.36636556169466933\n",
            "Accuracy: 0.8572\n",
            "Training loss:  0.3653189460796588\n",
            "Accuracy: 0.8539\n",
            "Training loss:  0.362721811003014\n",
            "Accuracy: 0.8505\n",
            "Training loss:  0.3591333365262444\n",
            "Accuracy: 0.8483\n",
            "Training loss:  0.3588864745806529\n",
            "Accuracy: 0.8544\n",
            "Training loss:  0.36392952365947684\n",
            "Accuracy: 0.8501\n",
            "Training loss:  0.35377908075478537\n",
            "Accuracy: 0.8596\n",
            "Training loss:  0.35124162455865826\n",
            "Accuracy: 0.8497\n",
            "Training loss:  0.3471319661783511\n",
            "Accuracy: 0.8565\n",
            "Training loss:  0.34137591429706066\n",
            "Accuracy: 0.8527\n",
            "Training loss:  0.35189166124949833\n",
            "Accuracy: 0.8503\n",
            "Training loss:  0.3417071346948142\n",
            "Accuracy: 0.8623\n",
            "Training loss:  0.34444358412708553\n",
            "Accuracy: 0.8543\n",
            "Training loss:  0.3451081605306439\n",
            "Accuracy: 0.8553\n",
            "Training loss:  0.3494975119988039\n",
            "Accuracy: 0.8436\n",
            "Training loss:  0.33563691307740934\n",
            "Accuracy: 0.8584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0vOz-MHbQbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = {'input_size': 784,\n",
        "              'output_size': 10,\n",
        "            'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "            'state_dict': model.state_dict()}\n",
        "torch.save(checkpoint, 'checkpoint.pth')            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}